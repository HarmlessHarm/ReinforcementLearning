{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing gradients: VPG and NPG\n",
    "The functionalities in this notebook can be used to plot the vanilla policy gradient and natural policy gradient for the examples in exercise 7.3 and 8.1 respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MU_MAX = 1.25\n",
    "MU_MIN = -0.25\n",
    "SIGMA_MIN = 0.0001\n",
    "SIGMA_MAX = 1\n",
    "PLOT_Y_EXCESS = 0.025\n",
    "PLOT_X_EXCESS = 0.05\n",
    "\n",
    "ARROW_WIDTH = 0.007\n",
    "ARROW_SCALE = 20\n",
    "ARROWS_PER_DIM = 11\n",
    "\n",
    "CONTOUR_POINTS = 50\n",
    "CONTOUR_LEVELS = 100\n",
    "\n",
    "K_VALUES = [0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info\n",
    "This code will allow you to generate nice plots that you can use to compare VPG and NPG. Inspect the code (you do not have to understand every detail). You will need to implement two methods which calculate gradients. These are used in *plot_normalized_grads* function. Additionally, you need to implement *expected_reward* function which is used in *plot_contour*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contour(ax, k):\n",
    "    \"\"\"\n",
    "    Plots contour the color of which corresponds to expected reward\n",
    "    :param ax: Ax used for plotting\n",
    "    :param k: Hyperparameter k\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create meshgrids for plotting \n",
    "    mu_grid, sigma_grid = torch.meshgrid(torch.linspace(MU_MIN - PLOT_X_EXCESS,\n",
    "                                                        MU_MAX + PLOT_X_EXCESS,\n",
    "                                                        CONTOUR_POINTS),\n",
    "                                         torch.linspace(SIGMA_MIN - PLOT_Y_EXCESS, \n",
    "                                                        SIGMA_MAX + PLOT_Y_EXCESS,\n",
    "                                                        CONTOUR_POINTS))\n",
    "    \n",
    "    # Transform from distribution parameters to theta parameters\n",
    "    theta_mu = mu_grid\n",
    "    theta_sigma = sigma_grid / k\n",
    "    \n",
    "    # Get expected rewards for all parameter combinations\n",
    "    r = expected_reward(theta_mu, theta_sigma, k)\n",
    "    ax.contourf(mu_grid, sigma_grid, r, levels=torch.linspace(torch.min(r),torch.max(r), CONTOUR_LEVELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normalized_grads(ax, grad_function, k):\n",
    "    \"\"\"\n",
    "    Plot the direction of gradients (gradients are normalized to unit length)\n",
    "    :param ax: ax used for plotting\n",
    "    :param grad_function: a function that is used to calculate the gradient\n",
    "    :param k: hyperparameter k\n",
    "    \"\"\"\n",
    "    # Create meshgrids to get all combinations of params\n",
    "    mu_grid, sigma_grid = torch.meshgrid(torch.linspace(MU_MIN, MU_MAX, ARROWS_PER_DIM),\n",
    "                                         torch.linspace(SIGMA_MIN, SIGMA_MAX, ARROWS_PER_DIM))\n",
    "    \n",
    "    # Flatten to make grad calculation easier\n",
    "    mus = mu_grid.contiguous().view(-1,1)\n",
    "    sigmas = sigma_grid.contiguous().view(-1,1)\n",
    "    \n",
    "    # Transform from distribution parameters to theta parameters\n",
    "    theta_mu = mus\n",
    "    theta_sigma = sigmas / k\n",
    "    \n",
    "    # Calculate gradients\n",
    "    g = grad_function(mu_params=theta_mu, sigma_params=theta_sigma, k=k)\n",
    "    \n",
    "    # Transform change wrt. theta_sigma to sigma dimension\n",
    "    g[:, 1] = g[:, 1] * k\n",
    "    \n",
    "    # Normalize gradient\n",
    "    g = g / g.norm(dim=1, keepdim=True)\n",
    "    ax.quiver(mus, sigmas, g[:, 0], g[:, 1], scale=ARROW_SCALE, width=ARROW_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(fig, plot_npg=False):\n",
    "    \"\"\"\n",
    "    Creates plot with VPG (and optionally NPG) gradients\n",
    "    :param fig: figure used for plotting\n",
    "    :param plot_npg: if set to true also adds NPG gradients to the plot\n",
    "    \"\"\"\n",
    "    n_k_values = len(K_VALUES)\n",
    "    \n",
    "    for i in range(1 + plot_npg):\n",
    "        for j in range(n_k_values):\n",
    "            ax = fig.add_subplot(1 + plot_npg, n_k_values, i * n_k_values + j + 1)\n",
    "            \n",
    "            # Set up ax and grad function\n",
    "            if i == 0:\n",
    "                ax.set_title(\"Vanilla policy grad k={}\".format(K_VALUES[j]))\n",
    "                grad_function = vanilla_grad\n",
    "            else:\n",
    "                ax.set_title(\"Natural policy grad k={}\".format(K_VALUES[j]))\n",
    "                grad_function = natural_grad\n",
    "            ax.set_xlabel(\"Mu\")\n",
    "            ax.set_ylabel(\"Sigma\")\n",
    "            ax.set_aspect(1)\n",
    "            ax.set_ylim(SIGMA_MIN-PLOT_Y_EXCESS, SIGMA_MAX + PLOT_Y_EXCESS)\n",
    "            ax.set_xlim(MU_MIN - PLOT_X_EXCESS, MU_MAX + PLOT_X_EXCESS)\n",
    "            \n",
    "            plot_contour(ax=ax, k=K_VALUES[j])\n",
    "            plot_normalized_grads(ax=ax, grad_function=grad_function, k=K_VALUES[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "Use results from the exercise and implement functions that calculate both gradient as well as expected reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTED BY STUDENT\n",
    "import time\n",
    "def vanilla_grad(mu_params, sigma_params, k):\n",
    "    \"\"\"\n",
    "    Calculates VPG using parameters mu and sigma and hyperparameter k \n",
    "    :param mu_params: tensor (Mx1) with mu parameters\n",
    "    :param sigma_params: tensor (Mx1) with sigma parameters\n",
    "    :param k: Hyperparameter k\n",
    "    :returns: tensor (Mx2) with gradients wrt. mu and sigma\n",
    "    \"\"\"\n",
    "    return torch.cat((1 - 2 * mu_params, -2 * k**2 * sigma_params), 1)\n",
    "    \n",
    "    \n",
    "def natural_grad(mu_params, sigma_params, k):\n",
    "    \"\"\"\n",
    "    Calculates NPG using parameters mu and sigma and hyperparameter k \n",
    "    :param mu_params: tensor (Mx1) with mu parameters\n",
    "    :param sigma_params: tensor (Mx1) with sigma parameters\n",
    "    :param k: Hyperparameter k\n",
    "    :returns: tensor (Mx2) with gradients wrt. mu and sigma\n",
    "    \"\"\"\n",
    "    mus = (1 - 2 * mu_params) * k**2 * sigma_params**2\n",
    "    sigs = (-1 * k**2 * sigma_params) * 0.5 * sigma_params**2\n",
    "    return torch.cat((mus, sigs), 1)\n",
    "\n",
    "def expected_reward(mu_params, sigma_params, k):\n",
    "    \"\"\"\n",
    "    Calculates exewcted reward using parameters mu and sigma and hyperparameter k \n",
    "    :param mu_params: tensor (Mx1) with mu parameters\n",
    "    :param sigma_params: tensor (Mx1) with sigma parameters\n",
    "    :param k: Hyperparameter k\n",
    "    :returns: tensor (Mx1) with expected rewards\n",
    "    \"\"\"\n",
    "    return mu_params - mu_params ** 2 - (k * sigma_params) ** 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VPG plot\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "create_plot(fig, plot_npg=False)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"vpg_plot.pdf\", dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NPG plot\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "create_plot(fig, plot_npg=True)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"npg_plot.pdf\", dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
